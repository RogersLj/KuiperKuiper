7767517
9 8
pnnx.Input               pnnx_input_0             0 1 0 #0=(1,3,4,4)f32
nn.Conv2d                conv1                    1 1 0 1 bias=True dilation=(1,1) groups=1 in_channels=3 kernel_size=(3,3) out_channels=3 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(3)f32 @weight=(3,3,3,3)f32 #0=(1,3,4,4)f32 #1=(1,3,4,4)f32
nn.Conv2d                conv2                    1 1 1 2 bias=True dilation=(1,1) groups=1 in_channels=3 kernel_size=(3,3) out_channels=3 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(3)f32 @weight=(3,3,3,3)f32 #1=(1,3,4,4)f32 #2=(1,3,4,4)f32
pnnx.Expression          pnnx_expr_2              2 1 2 0 3 expr=add(@0,@1) #2=(1,3,4,4)f32 #0=(1,3,4,4)f32 #3=(1,3,4,4)f32
nn.ReLU                  relu                     1 1 3 4 #3=(1,3,4,4)f32 #4=(1,3,4,4)f32
nn.AdaptiveAvgPool2d     avgpool                  1 1 4 5 output_size=(2,2) #4=(1,3,4,4)f32 #5=(1,3,2,2)f32
torch.flatten            torch.flatten_0          1 1 5 6 end_dim=-1 start_dim=1 $input=5 #5=(1,3,2,2)f32 #6=(1,12)f32
nn.Linear                linear                   1 1 6 7 bias=True in_features=12 out_features=4 @bias=(4)f32 @weight=(4,12)f32 #6=(1,12)f32 #7=(1,4)f32
pnnx.Output              pnnx_output_0            1 0 7 #7=(1,4)f32
